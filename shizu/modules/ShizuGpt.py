# â–ˆ â–ˆâ€ƒâ–ˆâ€ƒâ–ˆâ–„â–€â€ƒâ–„â–€â–ˆâ€ƒâ–ˆâ–€â–„â–€â–ˆâ€ƒâ–ˆâ–€â–ˆâ€ƒâ–ˆâ–€â–ˆâ€ƒâ–ˆ â–ˆ
# â–ˆâ–€â–ˆâ€ƒâ–ˆâ€ƒâ–ˆ â–ˆâ€ƒâ–ˆâ–€â–ˆâ€ƒâ–ˆ â–€ â–ˆâ€ƒâ–ˆâ–„â–ˆâ€ƒâ–ˆâ–€â–„â€ƒâ–ˆâ–„â–ˆ

# ğŸ”’ Licensed under the GNU GPLv3
# ğŸŒ https://www.gnu.org/licenses/agpl-3.0.html
# ğŸ‘¤ https://t.me/hikamoru

import re
import requests

from pyrogram import types, Client
from .. import loader, utils

# https://raw.githubusercontent.com/MoriSummerz/ftg-mods/main/chatgpt.py


@loader.module("ShizuGpt", "hikamoru", 1.0)
class ShizuGpt(loader.Module):
    """ChatGPT AI API interaction"""

    strings = {
        "set": "<emoji id=5021905410089550576>âœ…</emoji> <b>GPT key has been set</b>",
        "what": "<emoji id=5789703785743912485>â”</emoji> What should I set?",
        "what_ask": "<emoji id=5789703785743912485>â”</emoji> What should I ask?",
        "no_token": "<emoji id=5789703785743912485>â”</emoji> Token not set.",
        "pending": "<emoji id=5819167501912640906>â”</emoji> <b>Your Question was:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ğŸ¤–</emoji> <b>Answer: </b> Wait...",
        "answer": "<emoji id=5819167501912640906>â”</emoji> <b>Your Question was:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ğŸ¤–</emoji> <b>Answer:</b> {}",
        "cfg_doc": "Here you can set your GPT key, you can get it here: https://platform.openai.com/",
    }

    strings_ru = {
        "set": "<emoji id=5021905410089550576>âœ…</emoji> <b>GPT ĞºĞ»ÑÑ‡ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½</b>",
        "what": "<emoji id=5789703785743912485>â”</emoji> Ğ§Ñ‚Ğ¾ Ğ½ÑƒĞ¶Ğ½Ğ¾ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ?",
        "what_ask": "<emoji id=5789703785743912485>â”</emoji> Ğ§Ñ‚Ğ¾ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ·Ğ°Ğ´Ğ°Ñ‚ÑŒ?",
        "no_token": "<emoji id=5789703785743912485>â”</emoji> Ğ¢Ğ¾ĞºĞµĞ½ Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½.",
        "pending": "<emoji id=5819167501912640906>â”</emoji> <b>Ğ’Ğ°Ñˆ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ğŸ¤–</emoji> <b>ĞÑ‚Ğ²ĞµÑ‚:</b> ĞĞ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ...",
        "answer": "<emoji id=5819167501912640906>â”</emoji> <b>Ğ’Ğ°Ñˆ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ğŸ¤–</emoji> <b>ĞÑ‚Ğ²ĞµÑ‚:</b> {}",
        "cfg_doc": "Ğ—Ğ´ĞµÑÑŒ Ğ²Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ ÑĞ²Ğ¾Ğ¹ GPT ĞºĞ»ÑÑ‡, Ğ²Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ĞµĞ³Ğ¾ Ğ·Ğ´ĞµÑÑŒ: https://platform.openai.com/",
    }

    strings_uz = {
        "set": "<emoji id=5021905410089550576>âœ…</emoji> <b>GPT kalit ornatildi</b>",
        "what": "<emoji id=5789703785743912485>â”</emoji> Nma ornatishim kerak?",
        "what_ask": "<emoji id=5789703785743912485>â”</emoji> Nma qoldiring?",
        "no_token": "<emoji id=5789703785743912485>â”</emoji> Token not set.",
        "pending": "<emoji id=5819167501912640906>â”</emoji> <b>Yozuv:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ğŸ¤–</emoji> <b>Javob:</b> O'qiyapman...",
        "answer": "<emoji id=5819167501912640906>â”</emoji> <b>Yozuv:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ğŸ¤–</emoji> <b>Javob:</b> {}",
        "cfg_doc": "Bu erda siz o'zingizning GPT kalitingizni o'rnatishingiz mumkin, uni ushbu manzilda olishingiz mumkin: https://platform.openai.com/",
    }

    strings_jp = {
        "set": "<emoji id=5021905410089550576>âœ…</emoji> <b>GPTã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¾ã—ãŸ</b>",
        "what": "<emoji id=5789703785743912485>â”</emoji> ä½•ã‚’è¨­å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
        "what_ask": "<emoji id=5789703785743912485>â”</emoji> ä½•ã‚’å°‹ã­ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
        "no_token": "<emoji id=5789703785743912485>â”</emoji> ãƒˆãƒ¼ã‚¯ãƒ³ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
        "pending": "<emoji id=5819167501912640906>â”</emoji> <b>ã‚ãªãŸã®è³ªå•ã¯:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ğŸ¤–</emoji> <b>ç­”ãˆ:</b> å¾…ã£ã¦ãã ã•ã„...",
        "answer": "<emoji id=5819167501912640906>â”</emoji> <b>ã‚ãªãŸã®è³ªå•ã¯:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ğŸ¤–</emoji> <b>ç­”ãˆ:</b> {}",
        "cfg_doc": "ã“ã“ã§ã¯GPTã‚­ãƒ¼ã‚’è¨­å®šã§ãã¾ã™ã€‚ã“ã“ã§å–å¾—ã§ãã¾ã™ï¼šhttps://platform.openai.com/",
    }

    strings_ua = {
        "set": "<emoji id=5021905410089550576>âœ…</emoji> <b>GPT ĞºĞ»ÑÑ‡ Ğ²ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¾</b>",
        "what": "<emoji id=5789703785743912485>â”</emoji> Ğ©Ğ¾ Ğ¿Ğ¾Ñ‚Ñ€Ñ–Ğ±Ğ½Ğ¾ Ğ²ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğ¸?",
        "what_ask": "<emoji id=5789703785743912485>â”</emoji> Ğ©Ğ¾ Ğ¿Ğ¾Ñ‚Ñ€Ñ–Ğ±Ğ½Ğ¾ Ğ·Ğ°Ğ¿Ğ¸Ñ‚Ğ°Ñ‚Ğ¸?",
        "no_token": "<emoji id=5789703785743912485>â”</emoji> Ğ¢Ğ¾ĞºĞµĞ½ Ğ½Ğµ Ğ²ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¾.",
        "pending": "<emoji id=5819167501912640906>â”</emoji> <b>Ğ’Ğ°Ñˆ Ğ·Ğ°Ğ¿Ğ¸Ñ‚Ğ°Ğ½Ğ½Ñ:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ğŸ¤–</emoji> <b>Ğ’Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´ÑŒ:</b> ĞÑ‡Ñ–ĞºÑƒĞ²Ğ°Ğ½Ğ½Ñ...",
        "answer": "<emoji id=5819167501912640906>â”</emoji> <b>Ğ’Ğ°Ñˆ Ğ·Ğ°Ğ¿Ğ¸Ñ‚Ğ°Ğ½Ğ½Ñ:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ğŸ¤–</emoji> <b>Ğ’Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´ÑŒ:</b> {}",
        "cfg_doc": "Ğ¢ÑƒÑ‚ Ğ²Ğ¸ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ Ğ²ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğ¸ ÑĞ²Ñ–Ğ¹ GPT ĞºĞ»ÑÑ‡, Ğ²Ğ¸ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ Ğ¾Ñ‚Ñ€Ğ¸Ğ¼Ğ°Ñ‚Ğ¸ Ğ¹Ğ¾Ğ³Ğ¾ Ñ‚ÑƒÑ‚: https://platform.openai.com/",
    }

    strings_kz = {
        "set": "<emoji id=5021905410089550576>âœ…</emoji> <b>GPT Ñ‚Ñ–Ñ€ĞºĞµĞ»Ğ´Ñ–</b>",
        "what": "<emoji id=5789703785743912485>â”</emoji> ĞĞµĞ½Ñ– Ğ¾Ñ€Ğ½Ğ°Ñ‚Ñƒ ĞºĞµÑ€ĞµĞº?",
        "what_ask": "<emoji id=5789703785743912485>â”</emoji> ĞĞµĞ½Ñ– ÑÒ±Ñ€Ğ°Ñƒ ĞºĞµÑ€ĞµĞº?",
        "no_token": "<emoji id=5789703785743912485>â”</emoji> Ğ¢Ğ¾ĞºĞµĞ½ Ğ¾Ñ€Ğ½Ğ°Ñ‚Ñ‹Ğ»Ğ¼Ğ°Ò“Ğ°Ğ½.",
        "pending": "<emoji id=5819167501912640906>â”</emoji> <b>Ğ¡Ò±Ñ€Ğ°Ò“Ñ‹Ò£Ñ‹Ğ·:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ğŸ¤–</emoji> <b>Ğ–Ğ°ÑƒĞ°Ğ±Ñ‹:</b> ĞšÒ¯Ñ‚Ñƒ...",
        "answer": "<emoji id=5819167501912640906>â”</emoji> <b>Ğ¡Ò±Ñ€Ğ°Ò“Ñ‹Ò£Ñ‹Ğ·:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ğŸ¤–</emoji> <b>Ğ–Ğ°ÑƒĞ°Ğ±Ñ‹:</b> {}",
        "cfg_doc": "ĞœÒ±Ğ½Ğ´Ğ° ÑÑ–Ğ· Ğ¾Ò“Ğ°Ğ½ Ñ‚Ò¯ÑÑ–Ğ½Ñ–ĞºÑ‚ĞµĞ¼Ğµ Ğ±ĞµÑ€ĞµÑ‚Ñ–Ğ½ GPT Ñ‚Ñ–Ñ€ĞºĞµĞ»Ğ³Ñ–Ò£Ñ–Ğ·Ğ´Ñ– Ğ¾Ñ€Ğ½Ğ°Ñ‚ÑƒÒ“Ğ° Ğ±Ğ¾Ğ»Ğ°Ğ´Ñ‹: https://platform.openai.com/",
    }

    def __init__(self):
        self.config = loader.ModuleConfig(
            "GPT_KEY", None, lambda m: self.strings("cfg_doc")
        )

    async def _make_request(
        self,
        method: str,
        url: str,
        headers: dict,
        data: dict,
    ) -> dict:
        """
        Makes an asynchronous HTTP request using the specified method, URL,
        headers, and data.

        Parameters:
            method (str): The HTTP method to use for the request.
            url (str): The URL to send the request to.
            headers (dict): The headers to include in the request.
            data (dict): The JSON data to include in the request body.

        Returns:
            dict: The JSON response from the server.
        """
        resp = await utils.run_sync(
            requests.request,
            method,
            url,
            headers=headers,
            json=data,
        )
        return resp.json()

    def _process_code_tags(self, text: str) -> str:
        return re.sub(
            r"`(.*?)`",
            r"<code>\1</code>",
            re.sub(r"```(.*?)```", r"<code>\1</code>", text, flags=re.DOTALL),
            flags=re.DOTALL,
        )

    async def _get_chat_completion(self, prompt: str, token: str) -> str:
        resp = await self._make_request(
            method="POST",
            url="https://api.openai.com/v1/chat/completions",
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {token}",
            },
            data={
                "model": "gpt-3.5-turbo",
                "messages": [{"role": "user", "content": prompt}],
            },
        )
        if resp.get("error", None):
            return f"ğŸš« {resp['error']['message']}"

        return resp["choices"][0]["message"]["content"]

    @loader.command()
    async def gpt(self, app: Client, message: types.Message):
        """Ask question to GPT"""
        args = message.get_args_raw()

        if not args:
            return await message.answer(self.strings("what_ask"))

        token = self.config["GPT_KEY"]
        if not token:
            return await message.answer(self.strings("no_token"))
        await message.answer(self.strings("pending").format(args))
        answer = await self._get_chat_completion(args, self.config["GPT_KEY"])
        await message.answer(
            self.strings("answer").format(args, self._process_code_tags(answer))
        )
